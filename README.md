# 파이썬 풀스택 뉴스 요약기

## 1. 프로젝트 개요

이 프로젝트는 네이트 스포츠 뉴스의 랭킹 상위 3개 기사를 실시간으로 크롤링하고, Perplexity AI 모델을 통해 각 기사를 핵심 내용만 요약하여 API 형태로 제공하는 서비스입니다. 사용자는 간단한 API 요청만으로 복잡한 과정 없이 깔끔하게 정제된 뉴스 요약 데이터를 받아볼 수 있습니다.

---

## 2. 핵심 개발 철학: 백엔드 우선 (Backend-First)

이 프로젝트는 **백엔드 우선(Backend-First)** 접근법을 따릅니다. 데이터의 흐름을 책임지는 핵심 엔진(크롤링, AI 연동, API 서버)을 먼저 완벽하게 구축하고, 마지막에 사용자에게 보여줄 인터페이스(GUI 등)를 연결하는 방식입니다.

#### 왜 이 접근법을 사용했는가?

자동차를 만들 때, 화려한 외관 디자인보다 엔진과 변속기, 조향 장치를 먼저 만드는 것과 같습니다. 핵심 기능이 완벽하게 작동하는 것을 먼저 보장해야, 이후에 발생하는 문제의 원인이 UI인지, 데이터 처리인지 명확하게 파악할 수 있습니다. 이는 특히 기능이 명확한 단기 프로젝트에서 매우 효과적인 전략입니다.

-   **장점 1: 명확한 문제 분리:** 백엔드 API가 정상적으로 작동한다면, 추후 GUI에서 발생하는 문제는 전적으로 프론트엔드 코드에 국한됩니다.
-   **장점 2: 재사용성:** 잘 만들어진 백엔드 API는 웹, 모바일 앱, 데스크톱 애플리케이션 등 어떤 프론트엔드와도 쉽게 결합할 수 있습니다.
-   **장점 3: 집중도 높은 개발:** 데이터 수집, 가공, 제공이라는 핵심 로직에 먼저 집중하여 서비스의 근간을 튼튼하게 만듭니다.

---

## 3. 시스템 아키텍처 및 데이터 흐름

```
[클라이언트]
     |
     | 1. API 요청 (GET /summarize-top3-news)
     V
+---------------------------------+
|    FastAPI 서버 (main.py)       |
|---------------------------------|
| 2. 크롤러 호출                  |-----> [crawler.py] ----> (네이트 뉴스 서버)
|    (crawl_nate_sports_news_top3)  |      - 상위 3개 기사 크롤링
|                                 |      - (제목, 링크, 본문) 반환
|    <----------------------------|
|                                 |
| 3. 요약기 동시 호출 (asyncio.gather) |
|    (summarize_text x 3)         |
|      |         |         |
|      |         |         `-----> [summarizer.py] -> (Perplexity AI API)
|      |         `---------------> [summarizer.py] -> (Perplexity AI API)
|      `-------------------------> [summarizer.py] -> (Perplexity AI API)
|                                 |
|    <----------------------------|
|      - 3개의 요약 결과 동시 취합   |
|                                 |
| 4. 최종 데이터 조합 및 JSON 응답  |
+---------------------------------+
     |
     | 5. 요약된 뉴스 데이터 수신
     V
[클라이언트]
```

---

## 4. 기술 스택 및 학습 포인트 (Why We Use It)

### Backend (Python)

-   **FastAPI**
    -   **Why?**: 최신 파이썬 API 개발의 표준입니다. `비동기(Async)`를 네이티브로 지원하여 매우 높은 성능을 보여주며, 코드에 타입 힌트만 추가하면 자동으로 완벽한 API 문서(`http://.../docs`)를 생성해 줍니다. 개발 속도와 실행 속도, 두 마리 토끼를 모두 잡을 수 있는 최고의 선택입니다.
-   **Uvicorn**

    -   **Why?**: FastAPI로 만든 애플리케이션을 실행시켜주는 고성능 `ASGI(Asynchronous Server Gateway Interface)` 서버입니다. FastAPI가 잘 설계된 자동차라면, Uvicorn은 그 차가 달릴 수 있는 고속도로 역할을 합니다.

-   **Requests** & **BeautifulSoup4**

    -   **Why?**: 파이썬 웹 크롤링의 '국민 조합'입니다. `Requests`는 매우 직관적이고 간편하게 웹 페이지의 HTML을 가져오고, `BeautifulSoup4`는 이 복잡한 HTML을 CSS 선택자(`soup.select(...)`)를 통해 마치 jQuery처럼 쉽게 탐색하고 데이터를 추출하게 해줍니다. 정적인 웹 페이지를 스크래핑하는 가장 쉽고 확실한 방법입니다.

-   **httpx** & **asyncio**

    -   **Why?**: **현대 파이썬 개발의 핵심입니다.** `Requests`가 동기 방식의 표준이라면, `httpx`는 비동기 방식의 표준입니다. FastAPI와 같은 비동기 환경에서 외부 API(Perplexity)를 호출할 때, `httpx`를 사용해야만 서버가 응답을 기다리는 동안 멈추지 않고 다른 요청을 처리할 수 있습니다.
    -   특히 `asyncio.gather`는 여러 개의 비동기 작업을 **동시에 실행**시켜주는 마법 같은 도구입니다. 3개의 기사를 순서대로 요약하면 (30초 + 30초 + 30초)가 걸릴 것을, 동시에 처리하여 총 30초 남짓으로 단축시켜 API의 응답성을 극대화합니다.

-   **python-dotenv**
    -   **Why?**: **보안은 기본입니다.** API 키와 같은 민감한 정보를 소스 코드에 직접 하드코딩하는 것은 매우 위험합니다. `python-dotenv`는 이런 정보들을 `.env` 파일에 분리하여 안전하게 관리하고, 코드에서는 환경 변수처럼 불러와 사용할 수 있게 해줍니다. Git에 `.env` 파일을 올리지 않는 것은 개발자의 기본 약속입니다.

### Package Management

-   **uv**
    -   **Why?**: `pip`과 `venv`를 합친 것보다 훨씬 빠른 차세대 파이썬 패키지 관리 도구입니다. Rust로 작성되어 매우 빠른 속도로 의존성을 해결하고 가상 환경을 구축합니다. `uv run`과 같은 명령어로 개발 편의성을 크게 향상시킵니다.

---

## 5. 개발 진행 순서 (우리의 여정)

1.  **Phase 1: 웹 크롤러 개발 (`crawler.py`)**

    -   `requests`와 `BeautifulSoup`으로 네이트 뉴스 랭킹 페이지 접속 및 HTML 파싱.
    -   브라우저 개발자 도구를 이용해 원하는 데이터(제목, 링크)의 CSS 선택자 분석 및 추출.
    -   각 기사 링크로 재접속하여 본문 추출, `decompose`를 이용한 불필요한 태그(광고 등) 제거 로직 구현.
    -   최종적으로 TOP 3 기사의 (제목, 링크, 본문)을 반환하는 함수 `crawl_nate_sports_news_top3` 완성.

2.  **Phase 2: AI 요약기 개발 (`summarizer.py`)**

    -   Perplexity AI API 연동을 위한 비동기 함수 `summarize_text` 구현.
    -   `.env` 파일을 통해 API 키를 안전하게 로드하는 로직 추가.
    -   `httpx`를 사용하여 비동기 HTTP 요청 기능 구현 및 상세한 예외 처리 추가.

3.  **Phase 3: API 서버 구축 및 연동 (`main.py`)**
    -   `FastAPI` 앱 초기화 및 `/summarize-top3-news` 엔드포인트 생성.
    -   크롤러 함수를 호출하여 원본 데이터 수급.
    -   `asyncio.gather`를 활용하여 3개의 기사 본문을 **동시에** 요약기에 전달하고 결과 취합.
    -   크롤링 데이터와 AI 요약 데이터를 최종적으로 조합하여 JSON 형태로 클라이언트에게 반환하는 로직 완성.
    -   `uvicorn`을 통해 서버 실행 및 API 문서 페이지에서 기능 테스트 완료.

---

## 6. 프로젝트 실행 방법

1.  **.env 파일 생성**

    -   프로젝트 루트 디렉터리에 `.env` 파일을 생성하고, 아래 내용으로 Perplexity API 키를 추가합니다.

    ```
    PPLX_API_KEY=여러분의_API_키를_입력하세요
    ```

2.  **필요한 라이브러리 설치**

    -   `uv`를 사용하여 필요한 모든 패키지를 설치합니다.

    ```bash
    uv add fastapi uvicorn python-dotenv httpx requests beautifulsoup4
    ```

3.  **API 서버 실행**

    -   `uv run` 명령어를 통해 `uvicorn` 서버를 실행합니다. `--reload` 옵션은 코드 변경 시 서버를 자동 재시작합니다.

    ```bash
    uv run uvicorn main:app --reload
    ```

4.  **API 테스트**
    -   웹 브라우저를 열고 `http://127.0.0.1:8000/docs` 로 접속합니다.
    -   `/summarize-top3-news` 엔드포인트의 **[Try it out]** -> **[Execute]** 버튼을 눌러 API 작동을 확인합니다.

---

## 7. 향후 개선 과제

-   **GUI 클라이언트 개발**: `PySide6`를 사용하여 이 API를 활용하는 데스크톱 뉴스 요약 뷰어 애플리케이션 제작.
-   **데이터베이스 연동**: 요약된 뉴스 데이터를 `SQLite`나 `PostgreSQL` 같은 데이터베이스에 저장하여, 과거 데이터 조회 및 분석 기능 추가.
-   **크롤러 확장**: 스포츠 뉴스 외에 종합, 연예 등 다른 카테고리의 뉴스도 선택적으로 크롤링할 수 있도록 기능 확장.
-   **배포**: `Docker`를 사용하여 프로젝트를 컨테이너화하고, 클라우드 서비스(AWS, GCP 등)에 배포하여 실제 서비스로 운영.
